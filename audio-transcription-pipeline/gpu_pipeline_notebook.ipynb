{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Audio Transcription Pipeline\n",
    "## Real-time therapy session processing with speaker diarization\n",
    "\n",
    "This notebook runs the complete audio processing pipeline on GPU:\n",
    "- Audio preprocessing\n",
    "- Whisper transcription (large-v3)\n",
    "- Speaker diarization (pyannote 3.1)\n",
    "- Performance metrics collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from src.pipeline_gpu import GPUTranscriptionPipeline\n",
    "\n",
    "print(\"✓ Pipeline imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "AUDIO_FILE = \"test_audio.mp3\"  # Upload your audio file to the instance\n",
    "NUM_SPEAKERS = 2\n",
    "WHISPER_MODEL = \"large-v3\"  # Options: base, small, medium, large-v3\n",
    "LANGUAGE = \"en\"\n",
    "\n",
    "# Check if audio file exists\n",
    "if not os.path.exists(AUDIO_FILE):\n",
    "    print(f\"❌ Audio file not found: {AUDIO_FILE}\")\n",
    "    print(\"\\nUpload your audio file using:\")\n",
    "    print(\"  scp -P <PORT> your_audio.mp3 root@<SSH_HOST>:~/test_audio.mp3\")\n",
    "else:\n",
    "    file_size_mb = os.path.getsize(AUDIO_FILE) / (1024 * 1024)\n",
    "    print(f\"✓ Audio file: {AUDIO_FILE} ({file_size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check audio duration\n",
    "from pydub import AudioSegment\n",
    "\n",
    "audio = AudioSegment.from_file(AUDIO_FILE)\n",
    "duration_secs = len(audio) / 1000\n",
    "duration_mins = duration_secs / 60\n",
    "\n",
    "print(f\"Audio Duration: {duration_mins:.1f} minutes ({duration_secs:.0f} seconds)\")\n",
    "print(f\"Sample Rate: {audio.frame_rate} Hz\")\n",
    "print(f\"Channels: {audio.channels}\")\n",
    "print(f\"Estimated processing time: {duration_mins * 0.15:.1f} - {duration_mins * 0.2:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "print(\"Initializing GPU pipeline...\\n\")\n",
    "\n",
    "pipeline = GPUTranscriptionPipeline(\n",
    "    whisper_model=WHISPER_MODEL\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Pipeline ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run processing\n",
    "print(\"=\"*60)\n",
    "print(\"PROCESSING AUDIO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = pipeline.process(\n",
    "    audio_path=AUDIO_FILE,\n",
    "    num_speakers=NUM_SPEAKERS,\n",
    "    language=LANGUAGE,\n",
    "    enable_diarization=True\n",
    ")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ PROCESSING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)\")\n",
    "print(f\"Speedup: {duration_secs / total_time:.2f}x real-time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display performance metrics\n",
    "perf = results.get('performance', {})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "stages = perf.get('stages', {})\n",
    "for stage, time_taken in stages.items():\n",
    "    print(f\"{stage:25s} {time_taken:8.2f}s\")\n",
    "\n",
    "gpu_metrics = perf.get('gpu_metrics', {})\n",
    "if gpu_metrics:\n",
    "    print(\"\\nGPU Metrics:\")\n",
    "    print(f\"  Provider: {gpu_metrics.get('provider', 'unknown')}\")\n",
    "    print(f\"  Device: {gpu_metrics.get('device', 'unknown')}\")\n",
    "    print(f\"  Peak VRAM: {gpu_metrics.get('peak_vram_gb', 0):.1f} GB\")\n",
    "    print(f\"  Avg Utilization: {gpu_metrics.get('avg_utilization_pct', 0):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display transcript statistics\n",
    "transcript = results.get('aligned_transcript', []) or results.get('transcript', [])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRANSCRIPT STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total segments: {len(transcript)}\")\n",
    "\n",
    "# Count by speaker\n",
    "speakers = {}\n",
    "for seg in transcript:\n",
    "    speaker = seg.get('speaker', 'Unknown')\n",
    "    speakers[speaker] = speakers.get(speaker, 0) + 1\n",
    "\n",
    "for speaker, count in sorted(speakers.items()):\n",
    "    print(f\"  {speaker}: {count} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display diarized transcript (first 50 segments)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIARIZED TRANSCRIPT (First 50 segments)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "current_speaker = None\n",
    "for i, seg in enumerate(transcript[:50]):\n",
    "    speaker = seg.get('speaker', 'Unknown')\n",
    "    text = seg.get('text', '').strip()\n",
    "    start = seg.get('start', 0)\n",
    "    \n",
    "    # Add speaker label when speaker changes\n",
    "    if speaker != current_speaker:\n",
    "        print(f\"\\n[{speaker}] ({start:.1f}s)\")\n",
    "        current_speaker = speaker\n",
    "    \n",
    "    print(f\"  {text}\")\n",
    "\n",
    "if len(transcript) > 50:\n",
    "    print(f\"\\n... ({len(transcript) - 50} more segments)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f\"gpu_results_{timestamp}.json\"\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✓ Results saved to: {output_file}\")\n",
    "print(f\"  File size: {os.path.getsize(output_file) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "pipeline.cleanup_models()\n",
    "print(\"\\n✓ GPU memory released\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

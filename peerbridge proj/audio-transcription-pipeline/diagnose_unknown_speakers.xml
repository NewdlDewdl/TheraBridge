<?xml version="1.0" encoding="UTF-8"?>
<diagnostic_prompt>
    <purpose>Analyze and diagnose "Unknown" speaker labels in audio diarization pipeline</purpose>

    <context>
        <system_description>
            Audio transcription pipeline combining OpenAI Whisper (transcription) with Pyannote (speaker diarization).
            The system aligns Whisper text segments with Pyannote speaker turns to produce speaker-labeled transcripts.
        </system_description>

        <problem_statement>
            Multiple segments are being labeled as "Unknown" speaker when diarization results don't sufficiently overlap with transcription segments.
            This occurs particularly at the beginning of recordings and during certain time periods.
        </problem_statement>
    </context>

    <analysis_request>
        <data_to_examine>
            <file path="tests/outputs/diarization_output.json">
                Check the following data structures:
                - speaker_turns: Array of diarization results with speaker, start, end times
                - diarized_segments: Array of aligned segments with text, speaker, timestamps
                - Compare first speaker turn start time vs first segment start time
            </file>
        </data_to_examine>

        <questions_to_answer>
            <question id="1">
                What is the time gap between audio start (0.0s) and first detected speaker turn?
                Are there Whisper segments in this gap that get labeled as "Unknown"?
            </question>

            <question id="2">
                What is the overlap threshold being used (currently 50%)?
                How many segments fail this threshold and why?
            </question>

            <question id="3">
                Are there patterns in where "Unknown" labels appear?
                - Beginning/end of recording
                - Between speaker transitions
                - During silence or background noise
                - Short utterances or interruptions
            </question>

            <question id="4">
                What percentage of total segments are labeled "Unknown"?
                What is the total duration of "Unknown" segments vs identified speakers?
            </question>
        </questions_to_answer>

        <diagnostic_steps>
            <step number="1">
                <action>Identify all "Unknown" segments</action>
                <analysis>
                    - Extract start/end times of each Unknown segment
                    - Check what speaker turns exist in those time ranges
                    - Calculate actual overlap percentages
                </analysis>
            </step>

            <step number="2">
                <action>Analyze diarization gaps</action>
                <analysis>
                    - Find time periods with no speaker turns
                    - Compare with Whisper segments in those periods
                    - Determine if these are silence, music, or undetected speech
                </analysis>
            </step>

            <step number="3">
                <action>Evaluate alignment algorithm</action>
                <analysis>
                    - Test different overlap thresholds (30%, 40%, 50%, 60%)
                    - Consider alternative alignment strategies:
                        * Nearest neighbor (assign to closest speaker turn)
                        * Interpolation (use previous/next speaker for gaps)
                        * Confidence-based (use diarization confidence scores)
                </analysis>
            </step>
        </diagnostic_steps>
    </analysis_request>

    <potential_root_causes>
        <cause priority="high">
            Diarization model not detecting speech at recording start (intro music/silence)
        </cause>
        <cause priority="high">
            50% overlap threshold too strict for short segments or speaker transitions
        </cause>
        <cause priority="medium">
            Whisper detecting non-speech audio (music, noise) as text
        </cause>
        <cause priority="medium">
            Time alignment mismatch between Whisper and Pyannote processing
        </cause>
        <cause priority="low">
            Speaker overlap/crosstalk confusing diarization
        </cause>
    </potential_root_causes>

    <proposed_solutions>
        <solution id="1">
            <title>Adjust Overlap Threshold</title>
            <description>
                Lower threshold from 50% to 30% for better coverage.
                Add fallback to nearest speaker if no overlap found.
            </description>
            <implementation>
                if best_overlap / seg_duration < 0.3:
                    # Find nearest speaker turn
                    best_speaker = find_nearest_speaker(seg_start, seg_end, turns)
            </implementation>
        </solution>

        <solution id="2">
            <title>Pre-process Audio</title>
            <description>
                Detect and skip non-speech intro/outro sections.
                Use VAD (Voice Activity Detection) to filter segments.
            </description>
        </solution>

        <solution id="3">
            <title>Interpolate Speaker Gaps</title>
            <description>
                For Unknown segments between same speakers, interpolate.
                If Unknown between SPEAKER_00 segments, assign to SPEAKER_00.
            </description>
        </solution>

        <solution id="4">
            <title>Use Diarization Confidence</title>
            <description>
                Pyannote provides confidence scores - use these to make better decisions.
                Only mark as Unknown if confidence is below threshold.
            </description>
        </solution>
    </proposed_solutions>

    <metrics_to_track>
        <metric>Percentage of Unknown segments before/after fix</metric>
        <metric>Average overlap percentage for assigned segments</metric>
        <metric>Distribution of Unknown segments across recording timeline</metric>
        <metric>Speaker turn coverage (% of audio time with assigned speaker)</metric>
    </metrics_to_track>

    <next_steps>
        <step>Run diagnostic analysis on current output file</step>
        <step>Test with different overlap thresholds</step>
        <step>Implement nearest-neighbor fallback</step>
        <step>Add metrics logging to alignment function</step>
        <step>Test on multiple audio samples to verify improvements</step>
    </next_steps>
</diagnostic_prompt>